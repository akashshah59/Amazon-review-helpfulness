{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "train_df = getDF('train.json.gz')\n",
    "test_df = getDF('test_Helpful.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "train_df['categories'] = train_df.categories.apply(lambda x: list(itertools.chain(*x))).apply(lambda x: [each.split(',') for each in x]).apply(lambda x: list(set(itertools.chain(*x))))\n",
    "test_df['categories'] = test_df.categories.apply(lambda x: list(itertools.chain(*x))).apply(lambda x: [each.split(',') for each in x]).apply(lambda x: list(set(itertools.chain(*x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_fit = train_df.categories.to_list()\n",
    "test_categories_fit = test_df.categories.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.MultiLabelBinarizer()\n",
    "\n",
    "lb.fit(categories_fit)\n",
    "train_cats = pd.DataFrame(lb.transform(categories_fit),columns = lb.classes_)\n",
    "test_cats = pd.DataFrame(lb.transform(test_categories_fit),columns = lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('categories',axis = 1,inplace = True)\n",
    "test_df.drop('categories',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_df,train_cats],axis = 1)\n",
    "test = pd.concat([test_df,test_cats],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful</th>\n",
       "      <th>...</th>\n",
       "      <th>ZiGiny</th>\n",
       "      <th>adidas</th>\n",
       "      <th>adidas Originals</th>\n",
       "      <th>bebe</th>\n",
       "      <th>cobian</th>\n",
       "      <th>crocs</th>\n",
       "      <th>dollhouse</th>\n",
       "      <th>indigo by Clarks</th>\n",
       "      <th>nicole</th>\n",
       "      <th>pediped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I655355328</td>\n",
       "      <td>U745881038</td>\n",
       "      <td>3.0</td>\n",
       "      <td>These are cute, but they are a little small.  ...</td>\n",
       "      <td>R115160670</td>\n",
       "      <td>05 20, 2014</td>\n",
       "      <td>Cute</td>\n",
       "      <td>1400544000</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I241092314</td>\n",
       "      <td>U023577405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I love the look of this bra, it is what I want...</td>\n",
       "      <td>R800651687</td>\n",
       "      <td>02 7, 2013</td>\n",
       "      <td>Beautiful but size runs small</td>\n",
       "      <td>1360195200</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoryID      itemID  reviewerID  rating  \\\n",
       "0           0  I655355328  U745881038     3.0   \n",
       "1           0  I241092314  U023577405     4.0   \n",
       "\n",
       "                                          reviewText  reviewHash   reviewTime  \\\n",
       "0  These are cute, but they are a little small.  ...  R115160670  05 20, 2014   \n",
       "1  I love the look of this bra, it is what I want...  R800651687   02 7, 2013   \n",
       "\n",
       "                         summary  unixReviewTime                      helpful  \\\n",
       "0                           Cute      1400544000  {'outOf': 0, 'nHelpful': 0}   \n",
       "1  Beautiful but size runs small      1360195200  {'outOf': 0, 'nHelpful': 0}   \n",
       "\n",
       "   ...  ZiGiny  adidas  adidas Originals  bebe  cobian  crocs  dollhouse  \\\n",
       "0  ...       0       0                 0     0       0      0          0   \n",
       "1  ...       0       0                 0     0       0      0          0   \n",
       "\n",
       "   indigo by Clarks  nicole  pediped  \n",
       "0                 0       0        0  \n",
       "1                 0       0        0  \n",
       "\n",
       "[2 rows x 1061 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpfulNess_train = pd.DataFrame(train_df.helpful.apply(lambda x: [x['outOf'],x['nHelpful']]).to_list(),columns = ['outOf','nHelpful'])\n",
    "\n",
    "helpfulNess_test = pd.DataFrame(test_df.helpful.apply(lambda x: [x['outOf']]).to_list(),columns = ['outOf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,helpfulNess_train],axis = 1)\n",
    "test = pd.concat([test,helpfulNess_test],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price analysis. Is it worth to keep this feature in our analysis? There does not seem to be too much variance in the prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8ca35bef90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.price.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['helpful','reviewHash','reviewText','price'],axis = 1,inplace = True)\n",
    "test.drop(['helpful','reviewHash','reviewText','price'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = train.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[0])\n",
    "day = train.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[1])\n",
    "year = train.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[2])\n",
    "\n",
    "month_test = test.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[0])\n",
    "day_test = test.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[1])\n",
    "year_test = test.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['reviewTime'],axis = 1,inplace = True)\n",
    "test.drop(['reviewTime'],axis = 1,inplace = True)\n",
    "train.drop(['unixReviewTime'],axis = 1,inplace = True)\n",
    "test.drop(['unixReviewTime'],axis = 1,inplace = True)\n",
    "\n",
    "train['day'] = day\n",
    "train['month'] = month\n",
    "train['year'] = year\n",
    "\n",
    "test['day'] = day_test\n",
    "test['month'] = month_test\n",
    "test['year'] = year_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['summary'],axis = 1,inplace = True)\n",
    "test.drop(['summary'], axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['price'] = train.price.fillna(0)\n",
    "#test['price'] = test.price.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem of being sparse. How can we reduce that dimensionality?\n",
    "### How do we select important features from this ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>Card Cases &amp; Money Organizers</th>\n",
       "      <th>Chemises &amp; Negligees</th>\n",
       "      <th>Costumes &amp; More</th>\n",
       "      <th>Crafts &amp; Sewing</th>\n",
       "      <th>Diaper Covers &amp; Underwear</th>\n",
       "      <th>Five &amp; Seven Stone Jewelry</th>\n",
       "      <th>...</th>\n",
       "      <th>crocs</th>\n",
       "      <th>dollhouse</th>\n",
       "      <th>indigo by Clarks</th>\n",
       "      <th>nicole</th>\n",
       "      <th>pediped</th>\n",
       "      <th>outOf</th>\n",
       "      <th>nHelpful</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I655355328</td>\n",
       "      <td>U745881038</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>05</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I241092314</td>\n",
       "      <td>U023577405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>02</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoryID      itemID  reviewerID  rating   Card Cases & Money Organizers  \\\n",
       "0           0  I655355328  U745881038     3.0                               0   \n",
       "1           0  I241092314  U023577405     4.0                               0   \n",
       "\n",
       "    Chemises & Negligees   Costumes & More   Crafts & Sewing  \\\n",
       "0                      0                 1                 0   \n",
       "1                      0                 0                 0   \n",
       "\n",
       "    Diaper Covers & Underwear   Five & Seven Stone Jewelry  ...  crocs  \\\n",
       "0                           0                            0  ...      0   \n",
       "1                           0                            0  ...      0   \n",
       "\n",
       "   dollhouse  indigo by Clarks  nicole  pediped  outOf  nHelpful  day  month  \\\n",
       "0          0                 0       0        0      0         0   20     05   \n",
       "1          0                 0       0        0      0         0    7     02   \n",
       "\n",
       "   year  \n",
       "0  2014  \n",
       "1  2013  \n",
       "\n",
       "[2 rows x 1059 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "l_item = LabelEncoder()\n",
    "l_item.fit(train.itemID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['itemID'] = l_item.transform(train.itemID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['itemID'] = l_item.transform(test.itemID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we account for the fact that the reviewer might be new? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_review = LabelEncoder()\n",
    "l_review.fit(train.reviewerID.append(test.reviewerID))\n",
    "\n",
    "train['reviewerID'] = l_review.transform(train.reviewerID)\n",
    "test['reviewerID'] = l_review.transform(test.reviewerID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalers = {}\n",
    "for i in range(train.shape[1]):\n",
    "    colname = train.columns[i]\n",
    "    scalers[colname] = StandardScaler()\n",
    "    train[colname] = scalers[colname].fit_transform(train[colname].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test.shape[1]):\n",
    "    colname = test.columns[i]\n",
    "    test[colname] = scalers[colname].transform(test[colname].to_numpy().reshape(-1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>Card Cases &amp; Money Organizers</th>\n",
       "      <th>Chemises &amp; Negligees</th>\n",
       "      <th>Costumes &amp; More</th>\n",
       "      <th>Crafts &amp; Sewing</th>\n",
       "      <th>Diaper Covers &amp; Underwear</th>\n",
       "      <th>Five &amp; Seven Stone Jewelry</th>\n",
       "      <th>...</th>\n",
       "      <th>crocs</th>\n",
       "      <th>dollhouse</th>\n",
       "      <th>indigo by Clarks</th>\n",
       "      <th>nicole</th>\n",
       "      <th>pediped</th>\n",
       "      <th>outOf</th>\n",
       "      <th>nHelpful</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>0.549252</td>\n",
       "      <td>0.855597</td>\n",
       "      <td>-1.113633</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>2.026411</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.207563</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>0.509141</td>\n",
       "      <td>-0.292471</td>\n",
       "      <td>0.920535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>-0.890609</td>\n",
       "      <td>-1.641091</td>\n",
       "      <td>-0.210875</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.207563</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>-0.983304</td>\n",
       "      <td>-1.120672</td>\n",
       "      <td>-0.102776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>-0.308782</td>\n",
       "      <td>-0.185840</td>\n",
       "      <td>-1.113633</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>2.026411</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>0.109534</td>\n",
       "      <td>0.150873</td>\n",
       "      <td>-0.294483</td>\n",
       "      <td>-0.292471</td>\n",
       "      <td>0.920535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>0.950422</td>\n",
       "      <td>0.542445</td>\n",
       "      <td>-0.210875</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.207563</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>1.083158</td>\n",
       "      <td>-0.292471</td>\n",
       "      <td>0.920535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>1.464373</td>\n",
       "      <td>-1.376117</td>\n",
       "      <td>0.691883</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>2.026411</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.049014</td>\n",
       "      <td>-0.019673</td>\n",
       "      <td>1.657175</td>\n",
       "      <td>0.259663</td>\n",
       "      <td>-0.102776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>-1.376712</td>\n",
       "      <td>-0.046935</td>\n",
       "      <td>-0.210875</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.049014</td>\n",
       "      <td>-0.019673</td>\n",
       "      <td>-0.753697</td>\n",
       "      <td>0.535730</td>\n",
       "      <td>-0.102776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>1.223323</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.691883</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.207563</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>0.509141</td>\n",
       "      <td>0.811797</td>\n",
       "      <td>-0.102776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>0.724514</td>\n",
       "      <td>-1.046525</td>\n",
       "      <td>0.691883</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.207563</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>-1.327715</td>\n",
       "      <td>-0.568538</td>\n",
       "      <td>0.920535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>1.362557</td>\n",
       "      <td>0.217073</td>\n",
       "      <td>-0.210875</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.207563</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>-0.294483</td>\n",
       "      <td>-1.120672</td>\n",
       "      <td>0.920535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.525734</td>\n",
       "      <td>-0.987551</td>\n",
       "      <td>1.156617</td>\n",
       "      <td>0.691883</td>\n",
       "      <td>-0.109532</td>\n",
       "      <td>-0.031797</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118986</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.207563</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>1.312765</td>\n",
       "      <td>-1.120672</td>\n",
       "      <td>-0.102776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoryID    itemID  reviewerID    rating   Card Cases & Money Organizers  \\\n",
       "0   -0.525734  0.549252    0.855597 -1.113633                       -0.109532   \n",
       "1   -0.525734 -0.890609   -1.641091 -0.210875                       -0.109532   \n",
       "2   -0.525734 -0.308782   -0.185840 -1.113633                       -0.109532   \n",
       "3   -0.525734  0.950422    0.542445 -0.210875                       -0.109532   \n",
       "4   -0.525734  1.464373   -1.376117  0.691883                       -0.109532   \n",
       "5   -0.525734 -1.376712   -0.046935 -0.210875                       -0.109532   \n",
       "6   -0.525734  1.223323    0.132763  0.691883                       -0.109532   \n",
       "7   -0.525734  0.724514   -1.046525  0.691883                       -0.109532   \n",
       "8   -0.525734  1.362557    0.217073 -0.210875                       -0.109532   \n",
       "9   -0.525734 -0.987551    1.156617  0.691883                       -0.109532   \n",
       "\n",
       "    Chemises & Negligees   Costumes & More   Crafts & Sewing  \\\n",
       "0              -0.031797          2.026411         -0.010001   \n",
       "1              -0.031797         -0.493483         -0.010001   \n",
       "2              -0.031797          2.026411         -0.010001   \n",
       "3              -0.031797         -0.493483         -0.010001   \n",
       "4              -0.031797          2.026411         -0.010001   \n",
       "5              -0.031797         -0.493483         -0.010001   \n",
       "6              -0.031797         -0.493483         -0.010001   \n",
       "7              -0.031797         -0.493483         -0.010001   \n",
       "8              -0.031797         -0.493483         -0.010001   \n",
       "9              -0.031797         -0.493483         -0.010001   \n",
       "\n",
       "    Diaper Covers & Underwear   Five & Seven Stone Jewelry  ...     crocs  \\\n",
       "0                   -0.019879                    -0.015654  ... -0.118986   \n",
       "1                   -0.019879                    -0.015654  ... -0.118986   \n",
       "2                   -0.019879                    -0.015654  ... -0.118986   \n",
       "3                   -0.019879                    -0.015654  ... -0.118986   \n",
       "4                   -0.019879                    -0.015654  ... -0.118986   \n",
       "5                   -0.019879                    -0.015654  ... -0.118986   \n",
       "6                   -0.019879                    -0.015654  ... -0.118986   \n",
       "7                   -0.019879                    -0.015654  ... -0.118986   \n",
       "8                   -0.019879                    -0.015654  ... -0.118986   \n",
       "9                   -0.019879                    -0.015654  ... -0.118986   \n",
       "\n",
       "   dollhouse  indigo by Clarks    nicole   pediped     outOf  nHelpful  \\\n",
       "0  -0.010247         -0.004472 -0.003873 -0.009487 -0.207563 -0.190219   \n",
       "1  -0.010247         -0.004472 -0.003873 -0.009487 -0.207563 -0.190219   \n",
       "2  -0.010247         -0.004472 -0.003873 -0.009487  0.109534  0.150873   \n",
       "3  -0.010247         -0.004472 -0.003873 -0.009487 -0.207563 -0.190219   \n",
       "4  -0.010247         -0.004472 -0.003873 -0.009487 -0.049014 -0.019673   \n",
       "5  -0.010247         -0.004472 -0.003873 -0.009487 -0.049014 -0.019673   \n",
       "6  -0.010247         -0.004472 -0.003873 -0.009487 -0.207563 -0.190219   \n",
       "7  -0.010247         -0.004472 -0.003873 -0.009487 -0.207563 -0.190219   \n",
       "8  -0.010247         -0.004472 -0.003873 -0.009487 -0.207563 -0.190219   \n",
       "9  -0.010247         -0.004472 -0.003873 -0.009487 -0.207563 -0.190219   \n",
       "\n",
       "        day     month      year  \n",
       "0  0.509141 -0.292471  0.920535  \n",
       "1 -0.983304 -1.120672 -0.102776  \n",
       "2 -0.294483 -0.292471  0.920535  \n",
       "3  1.083158 -0.292471  0.920535  \n",
       "4  1.657175  0.259663 -0.102776  \n",
       "5 -0.753697  0.535730 -0.102776  \n",
       "6  0.509141  0.811797 -0.102776  \n",
       "7 -1.327715 -0.568538  0.920535  \n",
       "8 -0.294483 -1.120672  0.920535  \n",
       "9  1.312765 -1.120672 -0.102776  \n",
       "\n",
       "[10 rows x 1059 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tried a couple of machine learning models , but RandomForestRegressor seems to work the best. Random Forest works best even without standardization. DecisionTree seems to give binary results. Nothing in between. MAE in RandomForests takes a lot of time to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Tokenizer to the model. Also considering length of the review as feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = stopwords.words('english'))\n",
    "train_text = vectorizer.fit_transform(train_df.reviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = vectorizer.transform(test_df.reviewText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Bag of Words model for summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "count_vectorizer = TfidfVectorizer(stop_words= stopwords.words('english'))\n",
    "train_summary = count_vectorizer.fit_transform(train_df.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary = count_vectorizer.transform(test_df.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "train_csr = scipy.sparse.csr_matrix(train.loc[:,train.columns != 'nHelpful'].apply(lambda x: x.astype('float64')).values)\n",
    "test_csr = scipy.sparse.csr_matrix(test.apply(lambda x: x.astype('float64')).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model training takes very less time  to train but gets a mae of about 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(preds,message):\n",
    "    predictions = pd.DataFrame([l_review.inverse_transform(test.reviewerID),l_item.inverse_transform(test.itemID),test.outOf.to_numpy(),preds]).T\n",
    "    predictions[0] = predictions[0] + '-' + predictions[1] + '-'\n",
    "    predictions[0] = predictions[0] + predictions[2].apply(lambda x: str(x).strip())\n",
    "    predictions.drop([1,2],axis = 1 ,inplace = True)\n",
    "    predictions.rename(columns = {0:'userID-itemID-outOf',3:'prediction'},inplace = True)\n",
    "    predictions.to_csv('predictions_first.csv',sep= ',',index = False)\n",
    "    !kaggle competitions submit -c dse220 -f predictions_first.csv -m 'Pure random Forest , no dimensionality reduction only removal of features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying clustering on categories columns. Reducing dimensionality of  the data. Branch only if you want to reduce dimensionality in some or the other way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns[5:1055]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on k value 2\n",
      "Working on k value 3\n",
      "Working on k value 10\n",
      "Working on k value 50\n",
      "Working on k value 100\n",
      "Working on k value 200\n",
      "Working on k value 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on k value 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=1000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=1000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=1000. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans,KMeans\n",
    "\n",
    "n = [2,3,10,50,100,200,500,1000]\n",
    "\n",
    "means = []\n",
    "\n",
    "for k in n:\n",
    "    print(\"Working on k value %d\"%k)\n",
    "    means.append(MiniBatchKMeans(n_clusters=k,init = 'k-means++',max_iter = 1).fit(train[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "\n",
    "for mean in means:\n",
    "    rmses.append(mean.score(test[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(n,rmses)\n",
    "plt.title('RMSE curve to determine number of clusters')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('RMSE values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like after 500 , the other dimensions add complexity for the model. Let's still fine tune between 200 and 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on k value 200\n",
      "Working on k value 250\n",
      "Working on k value 300\n",
      "Working on k value 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=350. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=350. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=350. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on k value 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=400. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=400. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=400. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on k value 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=450. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=450. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=450. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on k value 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    }
   ],
   "source": [
    "n = [200,250,300,350,400,450,500]\n",
    "\n",
    "means = []\n",
    "\n",
    "for k in n:\n",
    "    print(\"Working on k value %d\"%k)\n",
    "    means.append(MiniBatchKMeans(n_clusters=k,init = 'k-means++',max_iter = 1).fit(train[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "\n",
    "for mean in means:\n",
    "    rmses.append(mean.score(test[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(n,rmses)\n",
    "plt.title('RMSE curve to determine number of clusters')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('RMSE values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE still increasing. Thus lets assume there are 500 categories and cluster data to these 500 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean500 = means[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([' Card Cases & Money Organizers', ' Chemises & Negligees',\\n       ' Costumes & More', ' Crafts & Sewing', ' Diaper Covers & Underwear',\\n       ' Five & Seven Stone Jewelry', ' Holders & Racks', ' Mittens & Liners',\\n       ' Rompers & Overalls', ' Safety & Work Gloves',\\n       ...\\n       'ZiGiny', 'adidas', 'adidas Originals', 'bebe', 'cobian', 'crocs',\\n       'dollhouse', 'indigo by Clarks', 'nicole', 'pediped'],\\n      dtype='object', length=1050)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-a023d5746907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean500\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_transformed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1055\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2979\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2981\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1269\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m         )\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 raise KeyError(\n\u001b[1;32m   1162\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1163\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m                     )\n\u001b[1;32m   1165\u001b[0m                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([' Card Cases & Money Organizers', ' Chemises & Negligees',\\n       ' Costumes & More', ' Crafts & Sewing', ' Diaper Covers & Underwear',\\n       ' Five & Seven Stone Jewelry', ' Holders & Racks', ' Mittens & Liners',\\n       ' Rompers & Overalls', ' Safety & Work Gloves',\\n       ...\\n       'ZiGiny', 'adidas', 'adidas Originals', 'bebe', 'cobian', 'crocs',\\n       'dollhouse', 'indigo by Clarks', 'nicole', 'pediped'],\\n      dtype='object', length=1050)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "train_transformed = train[train.columns[0:5]]\n",
    "train_transformed['cluster'] = mean500.predict(train[cols])\n",
    "train = pd.concat([train_transformed,train[train.columns[1055:]]],axis = 1)\n",
    "\n",
    "test_transformed = test[test.columns[0:5]]\n",
    "test_transformed['cluster'] = mean500.predict(test[cols])\n",
    "test = pd.concat([test_transformed,test[test.columns[1055:]]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "train_csr = scipy.sparse.csr_matrix(train.loc[:,train.columns != 'nHelpful'].apply(lambda x: x.astype('float64')).values)\n",
    "test_csr = scipy.sparse.csr_matrix(test.apply(lambda x: x.astype('float64')).values)\n",
    "\n",
    "\n",
    "train_data = hstack((train_csr,train_text,train_summary))\n",
    "test_data = hstack((test_csr,test_text,test_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Skip dimensionality reduction and try whats happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "train_data = hstack((train_csr,train_text,train_summary))\n",
    "test_data = hstack((test_csr,test_text,test_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR takes a lot of time to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_csr_new,val_new, train_y , val_y = train_test_split(train_data,train['nHelpful'],test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=None, tol=0.0001, verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svr = LinearSVR(verbose = 1, C = 1)\n",
    "svr.fit(train_csr_new,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37086442887462445"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "#svr.predict(val_new\n",
    "\n",
    "mean_absolute_error(scalers['nHelpful'].inverse_transform(val_y),scalers['nHelpful'].inverse_transform(svr.predict(val_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=20, n_iter=5,\n",
       "             random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.decomposition import  TruncatedSVD\n",
    "\n",
    "# svd = TruncatedSVD(n_components=20)\n",
    "# svd.fit(train_csr_new)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# rf = RandomForestRegressor(max_features=None,n_estimators=256,verbose= 1)\n",
    "# rf.fit(svd.transform(train_csr_new),train_y)\n",
    "\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# mean_absolute_error(val_y,smooth_predictions(rf.predict(svd.transform(val_new))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07329296424956615"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lm = LinearRegression(normalize = True,n_jobs = -1)\n",
    "lm.fit(train_csr_new,train_y)\n",
    "mean_absolute_error(val_y,lm.predict(val_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4297545206997986"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(scalers['nHelpful'].inverse_transform(val_y),scalers['nHelpful'].inverse_transform(lm.predict(val_new)))\n",
    "#mean_absolute_error(val_y,smooth_predictions(lm.predict(val_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(max_features=None,n_estimators=10,verbose= 1,n_jobs = -1)\n",
    "rf.fit(train_csr_new,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of the linear regressor improves with normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -0.,  0., ...,  0.,  4.,  3.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06324948783012618"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(val_y,svr.predict(val_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 256 out of 256 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.33984375, 0.        , 0.85546875, ..., 0.        , 0.        ,\n",
       "       1.23828125])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_predictions(preds):\n",
    "    import numpy as np\n",
    "    for i in range(0,preds.shape[0]):\n",
    "        x = preds[i]\n",
    "        if x % 1 > 0.5:\n",
    "            preds[i] = np.ceil(x) \n",
    "        else: \n",
    "            preds[i] = np.floor(x)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/akash/.kaggle/kaggle.json'\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409k/409k [00:08<00:00, 50.9kB/s]\n",
      "Successfully submitted to DSE 220 - Project"
     ]
    }
   ],
   "source": [
    "make_predictions(preds,'Random Forest regressor with 256 estimators, took 3 hours to train. No Dimensionality reduction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tried max feature reduction to reduce the dimensionality of the text data too. This resulted in an increase in mae value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
