{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "train_df = getDF('train.json.gz')\n",
    "test_df = getDF('test_Helpful.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryID</th>\n",
       "      <th>categories</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women], [Clothing...</td>\n",
       "      <td>I655355328</td>\n",
       "      <td>U745881038</td>\n",
       "      <td>3.0</td>\n",
       "      <td>These are cute, but they are a little small.  ...</td>\n",
       "      <td>R115160670</td>\n",
       "      <td>05 20, 2014</td>\n",
       "      <td>Cute</td>\n",
       "      <td>1400544000</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Clothing, ...</td>\n",
       "      <td>I241092314</td>\n",
       "      <td>U023577405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I love the look of this bra, it is what I want...</td>\n",
       "      <td>R800651687</td>\n",
       "      <td>02 7, 2013</td>\n",
       "      <td>Beautiful but size runs small</td>\n",
       "      <td>1360195200</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Wedding Party Gif...</td>\n",
       "      <td>I408260822</td>\n",
       "      <td>U441384838</td>\n",
       "      <td>3.0</td>\n",
       "      <td>it's better on a man's hand.I didn't find it v...</td>\n",
       "      <td>R345042616</td>\n",
       "      <td>05 13, 2014</td>\n",
       "      <td>Good price but...</td>\n",
       "      <td>1399939200</td>\n",
       "      <td>{'outOf': 2, 'nHelpful': 2}</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Clothing, ...</td>\n",
       "      <td>I770448753</td>\n",
       "      <td>U654041297</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Comfortable and easy to wear for a day of shop...</td>\n",
       "      <td>R875466866</td>\n",
       "      <td>05 25, 2014</td>\n",
       "      <td>Easy, breezy</td>\n",
       "      <td>1400976000</td>\n",
       "      <td>{'outOf': 0, 'nHelpful': 0}</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Plus-Size,...</td>\n",
       "      <td>I919238161</td>\n",
       "      <td>U096604734</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I'm quite small and the XS fits me like a regu...</td>\n",
       "      <td>R317526520</td>\n",
       "      <td>07 30, 2013</td>\n",
       "      <td>Great shirt</td>\n",
       "      <td>1375142400</td>\n",
       "      <td>{'outOf': 1, 'nHelpful': 1}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoryID                                         categories      itemID  \\\n",
       "0           0  [[Clothing, Shoes & Jewelry, Women], [Clothing...  I655355328   \n",
       "1           0  [[Clothing, Shoes & Jewelry, Women, Clothing, ...  I241092314   \n",
       "2           0  [[Clothing, Shoes & Jewelry, Wedding Party Gif...  I408260822   \n",
       "3           0  [[Clothing, Shoes & Jewelry, Women, Clothing, ...  I770448753   \n",
       "4           0  [[Clothing, Shoes & Jewelry, Women, Plus-Size,...  I919238161   \n",
       "\n",
       "   reviewerID  rating                                         reviewText  \\\n",
       "0  U745881038     3.0  These are cute, but they are a little small.  ...   \n",
       "1  U023577405     4.0  I love the look of this bra, it is what I want...   \n",
       "2  U441384838     3.0  it's better on a man's hand.I didn't find it v...   \n",
       "3  U654041297     4.0  Comfortable and easy to wear for a day of shop...   \n",
       "4  U096604734     5.0  I'm quite small and the XS fits me like a regu...   \n",
       "\n",
       "   reviewHash   reviewTime                        summary  unixReviewTime  \\\n",
       "0  R115160670  05 20, 2014                           Cute      1400544000   \n",
       "1  R800651687   02 7, 2013  Beautiful but size runs small      1360195200   \n",
       "2  R345042616  05 13, 2014              Good price but...      1399939200   \n",
       "3  R875466866  05 25, 2014                   Easy, breezy      1400976000   \n",
       "4  R317526520  07 30, 2013                    Great shirt      1375142400   \n",
       "\n",
       "                       helpful  price  \n",
       "0  {'outOf': 0, 'nHelpful': 0}    NaN  \n",
       "1  {'outOf': 0, 'nHelpful': 0}    NaN  \n",
       "2  {'outOf': 2, 'nHelpful': 2}  19.99  \n",
       "3  {'outOf': 0, 'nHelpful': 0}  14.95  \n",
       "4  {'outOf': 1, 'nHelpful': 1}    NaN  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "train_df['categories'] = train_df.categories.apply(lambda x: list(itertools.chain(*x))).apply(lambda x: [each.split(',') for each in x]).apply(lambda x: list(set(itertools.chain(*x))))\n",
    "test_df['categories'] = test_df.categories.apply(lambda x: list(itertools.chain(*x))).apply(lambda x: [each.split(',') for each in x]).apply(lambda x: list(set(itertools.chain(*x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_fit = train_df.categories.to_list()\n",
    "test_categories_fit = test_df.categories.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.MultiLabelBinarizer()\n",
    "\n",
    "lb.fit(categories_fit)\n",
    "train_cats = pd.DataFrame(lb.transform(categories_fit),columns = lb.classes_)\n",
    "test_cats = pd.DataFrame(lb.transform(test_categories_fit),columns = lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('categories',axis = 1,inplace = True)\n",
    "test_df.drop('categories',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_df,train_cats],axis = 1)\n",
    "test = pd.concat([test_df,test_cats],axis = 1)\n",
    "\n",
    "# Uncomment to run without categories\n",
    "#train = train_df\n",
    "#test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpfulNess_train = pd.DataFrame(train_df.helpful.apply(lambda x: [x['outOf'],x['nHelpful']]).to_list(),columns = ['outOf','nHelpful'])\n",
    "\n",
    "helpfulNess_test = pd.DataFrame(test_df.helpful.apply(lambda x: [x['outOf']]).to_list(),columns = ['outOf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,helpfulNess_train],axis = 1)\n",
    "test = pd.concat([test,helpfulNess_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['helpful','reviewHash','reviewText','price'],axis = 1,inplace = True)\n",
    "test.drop(['helpful','reviewHash','reviewText','price'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = train.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[0])\n",
    "day = train.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[1])\n",
    "year = train.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[2])\n",
    "\n",
    "month_test = test.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[0])\n",
    "day_test = test.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[1])\n",
    "year_test = test.reviewTime.apply(lambda x: [each.replace(',','') for each in str(x).split(' ')]).apply(lambda x:x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['reviewTime'],axis = 1,inplace = True)\n",
    "test.drop(['reviewTime'],axis = 1,inplace = True)\n",
    "train.drop(['unixReviewTime'],axis = 1,inplace = True)\n",
    "test.drop(['unixReviewTime'],axis = 1,inplace = True)\n",
    "\n",
    "train['day'] = day.astype('int')\n",
    "train['month'] = month.astype('int')\n",
    "train['year'] = year.astype('int')\n",
    "\n",
    "test['day'] = day_test.astype('int')\n",
    "test['month'] = month_test.astype('int')\n",
    "test['year'] = year_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a feature for how many words there are in a Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/akash59/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "train['textLength'] = train_df.reviewText.apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "test['textLength'] = test_df.reviewText.apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "\n",
    "## Summary length does not work as well\n",
    "\n",
    "#train['summaryLength'] = train_df.summary.apply(lambda x:len(x.split(' ')))\n",
    "#test['summaryLength'] = test_df.summary.apply(lambda x:len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['summary'],axis = 1,inplace = True)\n",
    "test.drop(['summary'], axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['noSent'] = train_df.reviewText.apply(lambda x:len(nltk.sent_tokenize(x)))\n",
    "#test['noSent'] = test_df.reviewText.apply(lambda x:len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items will never be new, but reviewers will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "l_item = LabelEncoder()\n",
    "l_item.fit(train.itemID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['itemID'] = l_item.transform(train.itemID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['itemID'] = l_item.transform(test.itemID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_review = LabelEncoder()\n",
    "l_review.fit(train.reviewerID)\n",
    "\n",
    "train['reviewerID'] = l_review.transform(train.reviewerID)\n",
    "#test['reviewerID'] = l_review.transform(test.reviewerID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l_review.classes_ = np.append(l_review.classes_,'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns = set(test.reviewerID).difference(l_review.classes_)\n",
    "test['reviewerID'] = test.reviewerID.apply(lambda x: 'Unknown' if x in unknowns else x)\n",
    "test['reviewerID'] = l_review.transform(test.reviewerID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer for summary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#count_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))#,lowercase=True,ngram_range = (3,4),max_features = 50000,max_df = 0.5)\n",
    "#train_text = count_vectorizer.fit_transform(train_df.reviewText)\n",
    "#test_text = count_vectorizer.transform(test_df.reviewText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No need to scale Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scalers = {}\n",
    "# for i in range(train.shape[1]):\n",
    "#     colname = train.columns[i]is\n",
    "#     scalers[colname] = StandardScaler()\n",
    "#     train[colname] = scalers[colname].fit_transform(train[colname].to_numpy().reshape(-1,1))\n",
    "    \n",
    "# for i in range(test.shape[1]):\n",
    "#     colname = test.columns[i]\n",
    "#     test[colname] = scalers[colname].transform(test[colname].to_numpy().reshape(-1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_ = train['nHelpful']\n",
    "train = train.drop('nHelpful',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "train = scipy.sparse.csr_matrix(train.values)\n",
    "test = scipy.sparse.csr_matrix(test.values)\n",
    "\n",
    "# Comment to remove summary\n",
    "# train = hstack((train,train_text))\n",
    "# test = hstack((test,test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_csr_new,val_new, train_y , val_y = train_test_split(train,help_,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(verbose = 1,n_jobs = -1)\n",
    "rf.fit(train_csr_new,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_predictions(preds):\n",
    "    import numpy as np\n",
    "    for i in range(0,preds.shape[0]):\n",
    "        x = preds[i]\n",
    "        if x % 1 > 0.5:\n",
    "            preds[i] = np.ceil(x) \n",
    "        else: \n",
    "            preds[i] = np.floor(x)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17445"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(val_y,smooth_predictions(rf.predict(val_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_predictions(preds,message):\n",
    "    outof = pd.DataFrame(test_df.helpful.apply(lambda x: [x['outOf']]).to_list(),columns = ['outOf'])['outOf']\n",
    "    predictions = pd.DataFrame([test_df.reviewerID,test_df.itemID,outof,preds]).T\n",
    "    predictions.rename(columns = {'reviewerID':0,'itemID':1,'Unnamed 0':2,'Unnamed 1':3},inplace = True)\n",
    "    predictions[0] = predictions[0] + '-' + predictions[1] + '-'\n",
    "    predictions[0] = predictions[0].apply(lambda x: x.strip())\n",
    "    predictions[0] = predictions[0] + predictions['outOf'].apply(lambda x: str(int(x)).strip())\n",
    "    predictions.drop([1,'outOf'],axis = 1 ,inplace = True)\n",
    "    predictions.rename(columns = {0:'userID-itemID-outOf',2:'prediction'},inplace = True)\n",
    "    predictions.to_csv('predictions_latest.csv',sep= ',',index = False)\n",
    "    #!kaggle competitions submit -c dse220 -f predictions_first.csv -m 'Simplest Random Forsts ,without price ,category and anything'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=250, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-training with entire training data\n",
    "rf = RandomForestRegressor(n_estimators = 250,verbose = 1,n_jobs = -1)\n",
    "rf.fit(train,help_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 250 out of 250 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "preds = smooth_predictions(rf.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_predictions(preds,'nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0.16452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
